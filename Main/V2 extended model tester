import torch
import re
import numpy as np
import nltk
from nltk.stem.porter import PorterStemmer
import pandas as pd
from nltk.corpus import stopwords

data_file_path = "Data\\Datafiles\\spam_ham_dataset.csv"
df = pd.read_csv(data_file_path)


# Initialize stemmer and stopword set
stemmer = PorterStemmer()
nltk.download('stopwords')
stopword_set = set(stopwords.words('english'))

# Define the EmailClassifier class (same architecture as before)
class EmailClassifier(torch.nn.Module):
    def __init__(self):
        super(EmailClassifier, self).__init__()
        self.fc1 = torch.nn.Linear(50, 256)
        self.bn1 = torch.nn.BatchNorm1d(256)
        self.fc2 = torch.nn.Linear(256, 128)
        self.bn2 = torch.nn.BatchNorm1d(128)
        self.fc3 = torch.nn.Linear(128, 64)
        self.bn3 = torch.nn.BatchNorm1d(64)
        self.fc4 = torch.nn.Linear(64, 32)
        self.bn4 = torch.nn.BatchNorm1d(32)
        self.fc5 = torch.nn.Linear(32, 16)
        self.bn5 = torch.nn.BatchNorm1d(16)
        self.fc6 = torch.nn.Linear(16, 2)
        self.dropout = torch.nn.Dropout(0.5)
        self.leaky_relu = torch.nn.LeakyReLU()

    def forward(self, x):
        x = self.leaky_relu(self.bn1(self.fc1(x)))
        x = self.leaky_relu(self.bn2(self.fc2(x)))
        x = self.leaky_relu(self.bn3(self.fc3(x)))
        x = self.leaky_relu(self.bn4(self.fc4(x)))
        x = self.leaky_relu(self.bn5(self.fc5(x)))
        x = self.fc6(x)
        return x

# Load the GloVe embeddings (same as in the original script)
def load_glove_embeddings(file_path):
    embeddings = {}
    with open(file_path, 'r', encoding='utf-8') as file:
        for line in file:
            values = line.split()
            word = values[0]
            vector = np.asarray(values[1:], dtype='float32')
            embeddings[word] = vector
    return embeddings

glove_file_path = "Main\\Pre_trained_word_vectors\\glove.6B.50d.txt"
glove_embeddings = load_glove_embeddings(glove_file_path)

# Preprocess a single email
def preprocess_email(email_text, embeddings, embedding_dim=50):
    email_text = email_text.lower()
    email_text = re.sub(r'[^a-z0-9\s]', '', email_text)  # Remove punctuation
    words = email_text.split()
    words = [stemmer.stem(word) for word in words if word not in stopword_set]
    word_vectors = [embeddings.get(word, np.zeros(embedding_dim)) for word in words]
    if len(word_vectors) > 0:
        email_vector = np.mean(word_vectors, axis=0)
    else:
        email_vector = np.zeros(embedding_dim)  # Zero vector for empty email
    return torch.tensor(email_vector, dtype=torch.float32).unsqueeze(0)  # Add batch dimension

# Load the saved model
model = torch.load('email_classifier_model.pth')
model.eval()  # Set model to evaluation mode

True_values = df['label_num'].values


email_vector = []

for i in range(len(df)):
    email_vector.append(preprocess_email(df['text'].iloc[i], glove_embeddings))


# check every single email in the list email_vector and predict if it is spam or not
good = 0
count = 0


for i in range(len(email_vector)):
    output = model(email_vector[i])
    _, predicted = torch.max(output, 1)
    if predicted == 1 and True_values[i] == 1:
        good = good + 1
        count += 1
    elif predicted == 0 and True_values[i] == 0:
        good = good + 1
        count += 1
    elif predicted == 1 and True_values[i] == 0:
        count +=1
    elif predicted == 0 and True_values[i] == 1:
        count +=1
    else:
        print("Error in classification")

print(good/count)